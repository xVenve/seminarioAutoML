<div class="wiki-toc">
    <p class="wiki-toc-title">Tabla de contenidos</p>
    <p class="wiki-toc-section-1 wiki-toc-section">1. <a href="#introduccion">Introducción </a></p>
    <p class="wiki-toc-section-1 wiki-toc-section">2. <a href="#queEsAutoML">¿Qué es el AutoML? </a></p>
    <p class="wiki-toc-section-1 wiki-toc-section">3. <a href="#autofe">AutoFE – Automated Feature Engineering </a></p>
    <p class="wiki-toc-section-2 wiki-toc-section">3.1. <a href="#featureTools">FeatureTools</a></p>
    <p class="wiki-toc-section-1 wiki-toc-section">4. <a href="#hpo">HPO – Hyperparameter Optimization </a></p>
    <p class="wiki-toc-section-2 wiki-toc-section">4.1. <a href="#bayesian">Bayesian Optimization </a></p>
    <p class="wiki-toc-section-2 wiki-toc-section">4.2. <a href="#ann">Artificial Neural Networks (ANN) </a></p>
    <p class="wiki-toc-section-2 wiki-toc-section">4.3. <a href="#genetic">Genetic Algorithms </a></p>
    <p class="wiki-toc-section-2 wiki-toc-section">4.4. <a href="#cash">CASH </a></p>
    <p class="wiki-toc-section-2 wiki-toc-section">4.5. <a href="#multiHPO">Multi-Fidelity HPO </a></p>
    <p class="wiki-toc-section-2 wiki-toc-section">4.6. <a href="#evaluation">Evaluation </a></p>
    <p class="wiki-toc-section-1 wiki-toc-section">5. <a href="#nas">NAS – Neural Architecture Search </a></p>
    <p class="wiki-toc-section-2 wiki-toc-section">5.1. <a href="#espacioDeBusqueda">Espacio de búsqueda</a></p>
    <p class="wiki-toc-section-3 wiki-toc-section">5.1.1 <a href="#operacionesSecuenciales">Operaciones secuenciales por capa </a></p>
    <p class="wiki-toc-section-3 wiki-toc-section">5.1.2 <a href="#representacionBasadaEnCelulas">Representación basada en células </a></p>
    <p class="wiki-toc-section-3 wiki-toc-section">5.1.3 <a href="#estructuraJerarquica">Estructura jerárquica </a></p>
    <p class="wiki-toc-section-2 wiki-toc-section">5.2. <a href="#algoritmosDeBusqueda">Algoritmos de búsqueda </a></p>
    <p class="wiki-toc-section-3 wiki-toc-section">5.2.1 <a href="#busquedaAleatoria">Búsqueda aleatoria </a></p>
    <p class="wiki-toc-section-3 wiki-toc-section">5.2.2 <a href="#aprendizajePorRefuerzo">Aprendizaje por refuerzo </a></p>
    <p class="wiki-toc-section-3 wiki-toc-section">5.2.2 <a href="#algoritmosEvolutivos">Algoritmos evolutivos </a></p>
    <p class="wiki-toc-section-3 wiki-toc-section">5.2.3 <a href="#procesoProgresivo">Proceso progresivo de las decisiones </a></p>
    <p class="wiki-toc-section-2 wiki-toc-section">5.3. <a href="#estrategiaDeEvaluacion">Estrategia de evaluación</a></p>
    <p class="wiki-toc-section-3 wiki-toc-section">5.3.1 <a href="#entrenamientoCero">Entrenamiento desde cero</a></p>
    <p class="wiki-toc-section-3 wiki-toc-section">5.3.2 <a href="#proxyTask">Proxy task performance</a></p>
    <p class="wiki-toc-section-3 wiki-toc-section">5.3.2 <a href="#intercambioDeParametros">Intercambio de parámetros</a></p>
    <p class="wiki-toc-section-3 wiki-toc-section">5.3.3 <a href="#basadoEnPrediccion">Basado en predicciones</a></p>
    <p class="wiki-toc-section-1 wiki-toc-section">6. <a href="#ventajasInconvenientes">Ventajas e inconvenientes frente a enfoques tradicionales </a></p>
    <p class="wiki-toc-section-1 wiki-toc-section">7. <a href="#areasAplicacion">Áreas de aplicación en IA </a></p>
    <p class="wiki-toc-section-2 wiki-toc-section">7.1. <a href="#vision">Visión</a></p>
    <p class="wiki-toc-section-2 wiki-toc-section">7.2. <a href="#traduccion">Traducción</a></p>
    <p class="wiki-toc-section-2 wiki-toc-section">7.3. <a href="#entrenamientoDispositivos">Entrenamiento de dispositivos móviles </a></p>
    <p class="wiki-toc-section-2 wiki-toc-section">7.4. <a href="#dataMining">Data Mining</a></p>
    <p class="wiki-toc-section-2 wiki-toc-section">7.5. <a href="#blockchain">Blockchain</a></p>
    <p class="wiki-toc-section-1 wiki-toc-section">8. <a href="#casosDeUso">Casos específicos de uso </a></p>
    <p class="wiki-toc-section-2 wiki-toc-section">8.1. <a href="#caso1">Identificación de perros callejeros </a></p>
    <p class="wiki-toc-section-2 wiki-toc-section">8.2. <a href="#caso2">Predicción de accidentes de tráfico </a></p>
    <p class="wiki-toc-section-1 wiki-toc-section">9. <a href="#futurasAplicaciones">Futuras aplicaciones </a></p>
    <p class="wiki-toc-section-1 wiki-toc-section">10. <a href="#conclusiones">Conclusiones </a></p>
    <p class="wiki-toc-section-1 wiki-toc-section">11. <a href="#bibliografia">Bibliografía </a></p>
    <p class="wiki-toc-section-1 wiki-toc-section">12. <a href="#apendices">Apéndices </a></p>
    <p class="wiki-toc-section-1 wiki-toc-section">13. <a href="#preguntas">Preguntas </a></p>
    <p class="wiki-toc-section-1 wiki-toc-section">14. <a href="#creditos">Créditos </a></p>
</div>
<h1 style="text-align:center; font-family:'Linux Libertine', Georgia, Times, serif; font-size:28.8px;">AutoML</h1>

<h2 style="border-bottom:1px solid #a2a9b1; margin-top:1em; font-size:21px; font-family:'Linux Libertine', Georgia, Times, serif;" id="introduccion">Introducción</h2>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">En este proyecto se explicará en qué consiste la técnica de AutoML, que permite en la actualidad hacer mucho más accesible a todos el Machine Learning (Aprendizaje Automático) y su gran potencia para la resolución de problemas y automatización de tareas. Alejaremos esa visión oscura de que estas técnicas solo están al alcance de las grandes compañías que poseen a los mejores expertos del mercado.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Además de explicar en qué consiste, se verán los diferentes procesos que lo componen. No obstante se explorarán los principales tipos de problemas a los que se aplica, que son la Ingeniería Automática de Características (<a  href="#autofe">Automated Feature Engineering</a>), la Optimización de hiperparámetros (<a href="#hpo">Hyperparameter Optimization</a>) y la Búsqueda de Arquitectura Neuronales (<a href="#nas">Neural Architecture Search</a>).</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Una vez tengamos claro cómo funciona y de que es capaz, se pasará a hacer una reflexión sobre que nos puede ofrecer el AutoML con respecto al Machine Learning tradicional, realizando un balance de ventaja e inconvenientes de este.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Seguidamente, se explorarán las principales áreas de la inteligencia artificial en las que más destaca, en las que se contará que tiene que aportar.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Esto servirá como premisa antes de pasar a contemplar su potencia en una serie de casos de estudio en los que se han empleado estas técnicas para diferentes tipos de problemas y en los que ha resultado realmente útil.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">También se estudiarán cuáles son las posibles ampliaciones que se podrán hacer en un futuro a esta técnica, para cubrir problemas más complejos o en situaciones en las que todavía no se emplean técnicas de inteligencia artificial.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">En última instancia, completaremos este proyecto exponiendo cuáles han sido nuestras impresiones e ideas finales, reflexionando sobre las aplicaciones en diversos campos de las técnicas asociadas a AutoML.</p>

<h2 style="border-bottom:1px solid #a2a9b1; margin-top:1em; font-size:21px; font-family:'Linux Libertine', Georgia, Times, serif;" id="queEsAutoML">¿Qué es el AutoML?</h2>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">AutoML <a href="#ref:automlStateOfTheArt">[1]</a> (Automated Machine Learning) es un conjunto de herramientas unificadas para la construcción automática de modelos de aprendizaje automático con un bajo coste computacional. Este último punto es muy importante debido a que gracias a esto podemos insertar AutoML en diversidad de dispositivos, además de que pueda ser utilizado por una mayor cantidad de compañías que no dispongan de muchos recursos para esta clase de tecnologías.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Esto implica que su rango de aplicación sea muy alto y sea una técnica cuyo uso ha aumentado exponencialmente en estos últimos años, convirtiéndose en uno de los puntos de clave del proceso de negocio.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Una de las ventajas de un sistema basado en AutoML es que se pueden combinar dinámicamente varias técnicas como puede ser KNN o redes neuronales para optimizar el modelo generado. Para el uso de esta tecnología no se necesitan los mejores expertos del mercado laboral, sino que poseyendo un conjunto de datos suficientemente amplio y variado del dominio, junto con un objetivo claro se pueden alcanzar resultados verdaderamente fascinantes, incluso en aquellas técnicas más complejas  como las redes de neuronas profundas <a href="#ref:h2oAutoML">[2]</a>.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">AutoML se puede entender como un pipeline con 4 fases principales: preparación de los datos, ingeniería de las características (extracción de datos a partir de nuestro conocimiento del dominio), generación del modelo (separado en espacio de búsqueda y optimización de métodos) y evaluación del modelo. Estas fases son muy parecidas a las de la mayoría de las técnicas utilizadas en IA.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">La característica principal de AutoML es su capacidad para encontrar las características de los datos y la arquitectura que sean suficientemente buenas para el problema que buscamos resolver. En pocas palabras, es un generador automático de modelos de IA, que se adaptan a nuestro problema específicamente.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">A continuación, se muestra un ejemplo de <em>pipeline</em> en AutoML, cabe denotar que el contenido de cada fase, sobre todo el referente a la generación de modelo puede ser modificada:</p>
<p style="text-align:center;"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0950705120307516-gr1.jpg" alt="1-s2.0-S0950705120307516-gr1.jpg"></p>
<p align="center" style="font-family:sans-serif; font-size:12px; line-height:1.4em;">Visión general del pipeline de AutoML <a href="#ref:automlStateOfTheArt">[1]</a></p>

<h2 style="border-bottom:1px solid #a2a9b1; margin-top:1em; font-size:21px; font-family:'Linux Libertine', Georgia, Times, serif;" id="autofe">AutoFE – Automated Feature Engineering</h2>
<p align="justify" style="font-family:sans-serif;font-size:14px;line-height:1.6;">En aprendizaje automático, además de la creación de los modelos según la naturaleza de la tarea que se afronta, el uso de características relevantes es un factor crítico. Esto es así porque el proceso de aprendizaje se basa en la información disponible, condicionando de esta manera los resultados que se obtendrán.</p>
<p align="justify" style="font-family:sans-serif;font-size:14px;line-height:1.6;">La ingeniería de características (feature engineering <a href="#ref:autoFEpython">[3]</a>) es el proceso de generación de nuevas características, generalmente más complejas, a partir de datos disponibles para el entrenamiento de modelos de aprendizaje automático. Esta tarea suele ir acompañada de un proceso de selección de características (feature selection) para determinar aquellas que mejoran la predicción mientras se evita el sobreajuste u overfitting de los modelos al dominio sobre el que se trabaja.</p>
<p align="justify" style="font-family:sans-serif;font-size:14px;line-height:1.6;">La creación de nuevas características informativas requiere conocimiento del dominio sobre el que se trabaja, así como una experimentación tediosa con el fin de seleccionar aquellas que son relevantes para la generación de otras. Esto junto con la inherente subjetividad que acompaña a las decisiones tomadas por los humanos invita a tratar de buscar una metodología que pueda automatizar este proceso. Asimismo, se debe tener presente que extraer tantos aspectos relevantes como sean posibles de los datos que se dispone será crucial para alcanzar soluciones efectivas.</p>
<p align="justify" style="font-family:sans-serif;font-size:14px;line-height:1.6;"> El <strong>Automated Feature Engineering</strong> (AutoFE o Ingeniería de Características Automáticas) es el proceso automatizado de extracción y manipulación de la información disponible para aportar nuevas características que puedan ayudar en la generación de modelos de aprendizaje automático tanto de clasificación como de regresión. El objetivo es evitar que la carga de selección de características importantes y su posterior adaptación recaiga sobre el experto para que este pueda invertir más tiempo en la fase de modelación.</p>
<p align="justify" style="font-family:sans-serif;font-size:14px;line-height:1.6;"> Partiendo de una serie de tablas de datos relacionados, el AutoFE permite crear características significativas e interpretables de manera eficiente, mientras que de forma paralela se ahorra el tiempo a dedicar en la ingeniería de características.</p>
<p align="justify" style="font-family:sans-serif;font-size:14px;line-height:1.6;"> Entre las estrategias de construcción automática de características, se encuentran aquellas que tratan de abarcar el proceso realizando todas las tareas de manera simultánea (“<em>everything at once</em>”), lo que supone un alto coste en memoria, y aquellas que realizan el proceso de manera iterativa, con las que es posible dejar de lado características relevantes y la consumición de tiempo puede ser muy elevada. Encontrar un balance entre ambas estrategias será fundamental.</p>
<p align="justify" style="font-family:sans-serif;font-size:14px;line-height:1.6;">A continuación se presenta la principal herramienta que existe en este ámbito: <em>FeatureTools</em>.</p>

<h3 style="font-weight:bold; font-size:16.8px; font-family:sans-serif;" id="featureTools">FeatureTools</h3>
<p align="justify" style="font-family:sans-serif;font-size:14px;line-height:1.6;">FeatureTools <a href="#ref:autoFEtools">[4]</a> es una de las librerías de <em>Python</em> más populares para la extracción automática de características. Se encarga de generar matrices de características para aprendizaje automático partiendo de conjuntos de datos temporales y relacionales mediante el uso de una “síntesis profunda de características” (cabe mencionar que el término “profundo” se debe a que apila diversas características y no a que use aprendizaje profundo para ello).</p>
<p align="justify" style="font-family:sans-serif;font-size:14px;line-height:1.6;">Los dos principales tipos de operaciones sobre las que se apoya son:</p>
<ul>
    <li><p align="justify" style="font-family:sans-serif;font-size:14px;line-height:1.6;"><em>Entity</em> y <em>Entity-Set</em>: Entity es una tabla básica (un dataframe de Pandas) mientras que un Entity-Set es un conjunto de tablas relacionadas entre sí con atributos y métodos definidos.</p></li>
    <li><p align="justify" style="font-family:sans-serif;font-size:14px;line-height:1.6;"><em>Primitivos</em>: son operaciones básicas que pueden aplicarse sobre características, tales como max, min, mean, mode, etc. Este tipo se divide en dos subtipos:</p></li>
    <li>
        <p align="justify" style="font-family:sans-serif;font-size:14px;line-height:1.6;"><em>Agregaciones</em>: partiendo de información conectada entre tablas a través de una relación 1 a n, se genera un nuevo aspecto que sintetiza dicha información.</p>
        <p align="justify" style="font-family:sans-serif;font-size:14px;line-height:1.6;">Por ejemplo, supongamos que se dispone de una tabla que identifica a los clientes de una tienda y otra en la que se registran de manera única cada una de las compras que se realizan online en la misma. De esta manera, agrupando los clientes en la segunda tabla por su identificador sería posible crear un nuevo atributo en el dataset de clientes llamado numCompras que determine el número de compras que ha realizado cada uno de ellos.</p>
    </li>
    <li>
        <p align="justify" style="font-family:sans-serif;font-size:14px;line-height:1.6;"><em>Transformaciones</em>: al contrario que las asociaciones, estas se llevan a cabo sobre una única tabla y pretenden aportar nueva información explícita a partir de características ya existentes.</p>
        <p align="justify" style="font-family:sans-serif;font-size:14px;line-height:1.6;"> Retomando el ejemplo anterior, imaginemos que en la tabla de clientes se recoge la fecha de registro de este en la página web. Así, aplicando una transformación sería posible crear una nueva característica llamada añoReg que muestre el año, extraído de la fecha, en el que el cliente creó su usuario.</p>
    </li>
</ul>
<p align="justify" style="font-family:sans-serif;font-size:14px;line-height:1.6;">Siendo el framework más extensamente usado en AutoFE, existe una amplia cantidad de recursos fácilmente accesibles. Además, es la herramienta más completa para trabajar sobre bases de datos relacionales, pudiendo crear características primitivas personalizadas a partir de transformaciones y agregaciones.</p>
<p align="justify" style="font-family:sans-serif;font-size:14px;line-height:1.6;">De entre las limitaciones que presenta, no permite trabajar con datos desestructurados y es necesario llevar a cabo una normalización de la información en bases de datos no relacionales. Adicionalmente, la creación de una amplia cantidad de nuevas características puede dar lugar a la maldición de la dimensionalidad, aumentando así exponencialmente el volumen del espacio y dispersando los datos.</p>

<h2 style="border-bottom:1px solid #a2a9b1; margin-top:1em; font-size:21px; font-family:'Linux Libertine', Georgia, Times, serif;" id="hpo">HPO – Hyperparameter Optimization</h2>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;"> De la misma manera que se expuso anteriormente la trascendencia de realizar una buena selección de características partiendo de información existente en los datos de entrada para la construcción de modelos de aprendizaje automático, la selección de los hiperparámetros es un aspecto crítico para alcanzar soluciones competitivas.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;"> Este proceso de búsqueda de los hiperparámetros óptimos está lejos de tratarse de una tarea trivial, pues el espacio de los mismos tiende a ser amplio y la selección de una combinación apropiada de los parámetros a utilizar puede suponer una ardua búsqueda ciega —por ejemplo, ante técnicas como las redes neuronales en las que, pese a que puedan existir ciertas recomendaciones que permitan descartar algunos escenarios, su comportamiento como cajas negras dificulta este proceso—.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Entre los métodos más comunes que se utilizan en la actualidad de selección de hiperparámetros óptimos es posible encontrar los siguientes <a href="#ref:hpoTowards">[5]</a>:</p>
<ul>
    <li><p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;"><em><strong>Búsqueda manual</strong></em>: partiendo de la experiencia o juicio del experto, los parámetros se seleccionan manualmente. A través de un proceso iterativo de prueba y error, se evalúa la eficacia del modelo con una configuración concreta y se repite esta tarea con diferentes alternativas hasta que se encuentre una precisión del modelo satisfactoria.</p></li>
    <li><p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;"><em><strong>Búsqueda aleatoria</strong></em>: como bien indica su nombre, en este caso la selección de los parámetros se realiza de forma aleatoria, lo que permite —en caso de que se lleven a cabo un número significativo de experimentaciones— evaluar escenarios diferentes. En combinación con algunas técnicas de poda, permite desestimar de manera eficiente ciertas regiones del espacio de hiperparámetros.</p></li>
    <li><p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;"><strong><em>Grid Search</em></strong>: este es uno de los métodos más utilizados en la búsqueda de hiperparámetros óptimos durante la construcción de modelos de aprendizaje automático tales como series temporales, redes de neuronas artificiales, clasificadores, etc. Mediante la creación de una red (<em>grid</em>) de hiperparámetros y la selección de un estimador, es posible paralelizar una amplia cantidad de experimentaciones. Cabe destacar que con frecuencia este método se apoya en la técnica de validación cruzada, lo que permite evaluar los modelos testeados y seleccionar así el mejor de ellos.</p></li>
</ul>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Los hiperparámetros determinan la estructura que caracterizará el modelo a construir, tratando de minimizar el error o maximizar la precisión del mismo a través de la mejor combinación posible de dichos parámetros. La automatización de este problema libera a los expertos de una tarea tediosa y propensa a errores.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">El <strong>Hyperparameter Optimization</strong> (Automatización de Hiperparámetros o HPO) se centra en la búsqueda de configuraciones de hiperparámetros que favorezcan a un buen rendimiento de un modelo de aprendizaje automático dado.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">A continuación se describen las técnicas más relevantes de HPO <a href="#ref:hpoAutoML">[6]</a>:</p>

<h3 style="font-weight:bold; font-size:16.8px; font-family:sans-serif;" id="bayesian">Bayesian Optimization</h3>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">La Optimización Bayesiana se trata de una estrategia de optimización global el cual usa la probabilidad para encontrar el mínimo de una función. Su meta final es encontrar un valor de entrada para la función con el que pueda ofrecer un valor de salida lo más bajo posible.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Esta estrategia puede disminuir el número de iteraciones seleccionando los valores de entrada en función de los resultados previos. Esto favorecerá a las siguientes soluciones, puesto que la búsqueda se realizará de una manera más exacta al resultado deseado.</p>

<h3 style="font-weight:bold; font-size:16.8px; font-family:sans-serif;" id="ann">Artificial Neural Networks (ANN)</h3>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Para la tarea de optimización de hiperparámetros de las Redes de Neuronas Artificiales se debe tener en cuenta que el objetivo de este proceso es lograr un rendimiento final correcto de la red neuronal. Para ello, se deberá seleccionar los hiperparámetros correctos para así optimizar el proceso de entrenamiento, por ejemplo, la cantidad de capas ocultas de nodos entre las capas de entrada y de salida.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Hay que tener presente que la optimización de los hiperparámetros no es sencilla. Un método para reducir la dificultad durante la tarea de optimización es emplear valores que ya se han utilizado previamente en problemas similares a los que se está tratando actualmente. Otra estrategia posible sería mediante prueba y error o incluso a través de validación cruzada.</p>

<h3 style="font-weight:bold; font-size:16.8px; font-family:sans-serif;" id="genetic">Genetic Algorithms</h3>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Loa algoritmos genéticos emplean mecanismos de selección natural dentro del Aprendizaje Automático. Haciendo referencia al darwinismo y su selección natural, se le llama también algoritmos evolutivos. </p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Se podrá hacer uso de los hiperparámetros en muchos ejemplos relacionados con los algoritmos evolutivos, por ejemplo, en el caso de que se defina una población de N modelos junto a sus hiperparámetros, se llevará a cabo un cálculo de la precisión de cada modelo y al final optar por eliminar la mitad de los modelos y quedarnos con la otra mitad, estos últimos serán los más precisos y con ellos se generarán los hijos que poseerán hiperparámetros similares a los padres, de esta manera se obtendrá nuevamente la población de N modelos. Este proceso se podrá realizar varias veces obteniendo así, en algún momento, los mejores modelos posibles.</p>

<h3 style="font-weight:bold; font-size:16.8px; font-family:sans-serif;" id="cash">CASH (Combined Algorithms Selection and Hyperparameter Optimization)</h3>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Un sistema AutoML necesita de dos “componentes” esenciales para funcionar: la configuración óptima de los hiperparámetros y de un buen modelo. A este tipo de problema se le denomina problema HPO en el cual se podrá encontrar una jerarquía entre hiperparámetros, siendo el hiperparámetro superior el que selecciona el algoritmo que se va a emplear, mientras que los demás hiperparámetros son condicionados por este.</p>

<h3 style="font-weight:bold; font-size:16.8px; font-family:sans-serif;" id="multiHPO">Multi-Fidelity HPO</h3>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Hoy en día, el tamaño de los datos resulta ser bastante grande y, además, la complejidad de los modelos conlleva a que encontrar una configuración eficiente sea más complicado dentro del tiempo que se posee. Por ello, las estrategias de multifidelidad tienen como meta encontrar un valor real mucho más próximo de una función costosa y, como consecuencia de ello, la eficiencia del HPO aumenta considerablemente.</p>

<h3 style="font-weight:bold; font-size:16.8px; font-family:sans-serif;" id="evaluation">Evaluation</h3>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">En cuanto a la evaluación de AutoML y, en especial HPO, conllevan a muchos desafíos, esto es por varios motivos que serán comentados a continuación.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">El proceso repetitivo que llevan a cabo produce unos resultados muy complejos y costosos desde el punto de vista computacional, además de que los <i>benchmarks</i> al poseer ruido en algunos casos resulten poco significativos para su uso en el proceso de HPO.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Para solucionar este problema y reducir la carga computacional que conlleva estos procesos, se han creado varios paquetes, HPOBench para las evaluaciones comparativas de HPO y ACLib que contendrá una colección de referencia para la configuración de algoritmos.</p>

<h2 style="border-bottom:1px solid #a2a9b1; margin-top:1em; font-size:21px; font-family:'Linux Libertine', Georgia, Times, serif;" id="nas">NAS – Neural Architecture Search</h2>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Hoy en día, en las industrias, la eficiencia de una red neuronal es un tema de gran importancia. Esto es así debido a que se necesita de unas redes de neuronas que consigan generalizar los datos y no solo un pequeño subconjunto de datos, por ello, es necesario de la búsqueda de una arquitectura neuronal que sea lo más óptima posible. No obstante, esto no resulta ser así en todos los sectores, puesto que lo que se busca realmente es la productividad frente a la calidad por lo que se conforman con el primer modelo que obtienen y no siguen con la tarea de búsqueda esencial de un modelo que logre unos resultados de mayor calidad a los anteriores.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Por este motivo, la NAS tiene como meta encontrar la mejor arquitectura para una red neuronal. Este se encargará del proceso de configuración de una red neuronal que en un principio lo haría el ser humano. Tendrá que ver que funciona correctamente y, además, automatiza este proceso para así buscar nuevas arquitecturas más eficientes a las anteriores que produzcan unos resultados que mejor se adapten a los objetivos buscados.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">NAS, al ser un subcampo de AutoML, encapsula las tareas que automatizan los problemas de Deep Learning. NAS posee las siguientes propiedades siendo algunas positivas y otras negativas <a href="#ref:whatIsNAS">[7]</a>:</p>
<ul>
    <li><p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">NAS descubre la solución óptima entre un gran número de opciones y selecciona al que mejor se aproxime a los objetivos buscados.</p></li>
    <li><p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Emplea algoritmos basados en optimización.</p></li>
    <li><p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Costoso desde el punto de vista computacional.</p></li>
    <li><p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Es complejo averiguar cómo se va a comportar ante datos reales.</p></li>
</ul>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">A continuación se hará una explicación detallada de los 3 componentes de una NAS <a href="#ref:NAS2020">[8]</a>:</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Según una gran revisión de trabajos realizados publicada por Elsken en el año 2019,  la búsqueda de arquitecturas neuronales (NAS) puede caracterizarse como un sistema que tiene tres grandes componentes.</p>

<h3 style="font-weight:bold; font-size:16.8px; font-family:sans-serif;" id="espacioDeBusqueda">Espacio de búsqueda</h3>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Al fin y al cabo, como todo algoritmo de búsqueda debe definirse un <b>espacio de búsqueda </b>que acote el problema que se está intentando resolver y que define el dominio de las posibles soluciones. En el caso de NAS, el espacio de búsqueda consiste en una serie de operaciones o, acotando todavía más el problema, tipos de capas (e.g. convolucionales, totalmente conectadas, pooling); y una serie de posibles topologías (conexiones) entre estos componentes.</p>

<h4 style="font-weight:bold; font-size:14px; font-family:sans-serif;" id="operacionesSecuenciales">Operaciones secuenciales por capa</h4>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">El enfoque más cándido para definir el espacio de búsqueda es la discretización de los tipos de capas. De esta manera pueden definirse capas convolucionales, fully-connected, etc. Si embargo, esta discretización requiere de una gran cantidad de conocimiento experto, ya que los tipos de capas vienen definidas por los hiperparámetros y estos deben de ser fijados a priori. Además, las conexiones entre estas capas también deben tenerse en cuenta y limitarse. Para ello pueden definirse una serie de reglas adicionales como las propuestas por Zoph &amp; Lee en el 2017 <a href="#ref:NeuralArchitecture">[9]</a>.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Este tipo de enfoque es muy potente, pero el espacio de búsqueda se vuelve demasiado grande. Algunos de los experimentos realizados requirieron 800 GPUs durante 28 días <a href="#ref:DesigningNeural">[10]</a>. Otros restringen el espacio de búsqueda para que incluyese como máximo dos capas completamente conectadas. </p>
<p style="text-align:center;"><img src="https://aulaglobal.uc3m.es/draftfile.php/2631638/user/draft/292806929/Screenshot%202021-11-24%20at%2022.26.51.png" alt="" width="450" height="263" class="img-responsive atto_image_button_text-bottom"></p>
<p align="center" style="font-family:sans-serif; font-size:12px; line-height:1.4em;">Figura 5.1 <a href="#ref:NeuralArchitecture">[9]</a></p>

<h4 style="font-weight:bold; font-size:14px; font-family:sans-serif;" id="representacionBasadaEnCelulas">Representación basada en células</h4>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">En este caso el espacio de búsqueda propuesta está constituido por solo dos tipos de capas. Este enfoque fue usado para el reconocimiento de imágenes en el artículo académico “Learning transferable architectures for scalable image recognition” <a href="#ref:BowenBaker">[11]</a>. En pocas palabras este artículo proponía optimizar la arquitectura de la red, partiendo de un caso simplificado de imágenes de poca resolución y una sucesión predefinida de células normales y de reducción. Las capas normales mantienen la dimensión de las entradas, mientras que las capas de reducción la dividen por la mitad. De esta manera el problema de búsqueda de arquitectura se limita en encontrar la arquitectura de únicamente dos tipos de células que se mantendrá constante. Las pruebas necesarias para la búsqueda se llevan a cabo en el conjunto de imágenes de poca resolución para limitar el tiempo de búsqueda y luego la arquitectura se escala para aplicarla en el conjunto final de imágenes.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">El espacio de búsqueda se centra en una agrupación las salidas de cada una de estas células y las entradas originales en bloques llamados hidden states. El objetivo, por tanto, es decidir cómo generamos nuevos hidden states a partir de dos hidden states obtenidos de la salida de la capa anterior. Como se aprecia en la Figura 5.2, del conjunto de estados ocultos generados hasta el momento se escogen dos se aplica una operación (red neuronal) a cada uno de ellos para luego juntarlos utilizando otra operación (adición o concatenación). Por tanto, la arquitectura de una célula en concreto queda definida por las elecciones de pares de estados ocultos y por las operaciones que se realizan con ellos para producir nuevos bloques ocultos, tal y como se aprecia en la Figura 5.2 extraída del artículo citado. </p>
<p style="text-align:center;"><img src="https://aulaglobal.uc3m.es/draftfile.php/2631638/user/draft/292806929/image%20%284%29.png" alt=""></p>
<p align="center" style="font-family:sans-serif; font-size:12px; line-height:1.4em;">Figura 5.2 <a href="#ref:BowenBaker">[11]</a></p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Gracias a esta técnica el espacio de búsqueda se reduce considerable y con ello el tiempo de búsqueda. Asimismo, la técnica es fácilmente aplicable a otros conjuntos de datos y la idea de repetición de bloques uniformes puede ser replicada de distintas maneras.</p>

<h4 style="font-weight:bold; font-size:14px; font-family:sans-serif;" id="estructuraJerarquica">Estructura jerárquica</h4>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Ampliando la noción de repetición de bloques uniformes que se presentaba en la sección 1.2 es posible definir nuevos “caminos” más allá del patrón célula reducción-normal. En HNAS (Hierarchical Neural Architecture Search) <a href="#ref:LearningTransferable">[12]</a>, se plantea la creación jerárquica de “motivos” a partir de una serie de operaciones primitivas. De este modo, a partir de operaciones como por ejemplo convolución 1x1, convolución 3x3 y max-pooling 3x3 puede crearse un grafo dirigido tomando estas operaciones como nodos que represente el camino que siguen las entradas hasta llegar a la última operación (sink node). Con ese proceso se crearían nuevos motivos de nivel 2 y con esos motivos se volverían a crear nuevos grafos dirigidos sin ciclos que pertenecerían posteriormente a los motivos de nivel 3 y así sucesivamente.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">La formación de nuevos motivos se conoce como ensamble (ensamblar).</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;"></p>
<p style="text-align:center;"><img src="https://aulaglobal.uc3m.es/draftfile.php/2631638/user/draft/292806929/image%20%286%29.png" alt=""></p>
<p align="center" style="font-family:sans-serif; font-size:12px; line-height:1.4em;">Figura 5.3 <a href="#ref:LearningTransferable">[12]</a></p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;"></p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;"></p>

<h3 style="font-weight:bold; font-size:16.8px; font-family:sans-serif;" id="algoritmosDeBusqueda">Algoritmos de búsqueda</h3>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Una vez hemos descrito algunos de los muchos espacios de búsqueda que pueden usarse, queda responder a la pregunta más importante: ¿cómo vamos a encontrar la mejor arquitectura? En la realidad las estrategias seguidas son típicas en otros procesos de búsqueda dispares, así que nos centraremos en cómo poder aplicar estas técnicas al problema que nos atañe.</p>

<h4 style="font-weight:bold; font-size:14px; font-family:sans-serif;" id="busquedaAleatoria">Búsqueda aleatoria</h4>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">El enfoque más sencillo, aunque no por eso despreciable, es la evaluación de combinaciones aleatorias de bloques constructivos. En realidad, el método aleatorio de búsqueda ha resultado ser útil <a href="#ref:HierarchicalRepresentations">[13]</a>. En el paper citado del año 2012, se demuestra que la búsqueda aleatoria de hiperparámetros resulta ser más eficiente y da mejores resultados que los métodos tradicionales de búsqueda por rejilla o manual. Esto es así, ya que como se demuestra en el artículo los métodos convencionales tienden a sobre ajustarse demasiado a un único conjunto de datos algo que nos parece suceder con la búsqueda aleatoria.</p> 

<h4 style="font-weight:bold; font-size:14px; font-family:sans-serif;" id="aprendizajePorRefuerzo">Aprendizaje por refuerzo</h4>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Para aplicar el aprendizaje por refuerzo a NAS, definiremos las acciones que pueden ser llevadas a cabo por nuestro agente como una serie parámetros, operaciones y bloques dependiendo del espacio de búsqueda que usemos que definirán una red neuronal. Dicha acción obtiene una recompensa tras entrenar la red neuronal propuesta y evaluarla. En NAS
<a href="#ref:NeuralArchitecture">[9]</a> se utiliza el propio accuracy de la red como recompensa. En dicho artículo también se introduce un nuevo parámetro, loss, cuyo objetivo es funcionar como una especie ponderación para distribuir la recompensa a cada operación que compuso la acción aplicada.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">En la Figura 4, sacada del artículo mencionado, puede apreciarse la mejora respecto a la búsqueda aleatoria de los mejores modelos generados cada 400 pruebas de modelos.</p>
<p style="text-align:center;"><img src="https://aulaglobal.uc3m.es/draftfile.php/2631638/user/draft/292806929/image%20%283%29.png" alt=""></p>
<p align="center" style="font-family:sans-serif; font-size:12px; line-height:1.4em;">Figura 5.4 <a href="#ref:NeuralArchitecture">[9]</a></p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Se han utilizado también otros enfoques basados en Q-learning como es el caso de MetaQNN. En este caso definimos los estamos como todos los hiperparámetros de una red neuronal y operaciones por capas. Las acciones van modificando las conexiones entre capas, los propios tipos de las capas y otros parámetros. El valor Q indica cómo de seguros estamos de que una de esas acciones (por ejemplo, la conexión entre una capa convolucional y una de pooling) conlleva una mejor accuracy.</p>

<h4 style="font-weight:bold; font-size:14px; font-family:sans-serif;" id="algoritmosEvolutivos">Algoritmos evolutivos</h4>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">En primer lugar, para poder aplicar algoritmos evolutivos debemos decidir cuál va a ser la codificación del espacio de búsqueda. Un ejemplo de esto <a href="#ref:RandomSearch">[14]</a> sería tomar las propias conexiones de la red neuronal y sus pesos como codificación. De esta manera cada gen contiene la arquitectura completa de la red. Posteriormente, se realizan las operaciones típicas de los algoritmos evolutivos (mutación, cruce, etc.)  para obtener nuevas redes/individuos.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Otro ejemplo, <a href="#ref:EvolvingNeural">[15]</a> en el que se ilustra el proceso por completo de un algoritmo genético nos servirá para comprender cómo pueden aplicarse los algoritmos genéticos a estos modelos. En esta ocasión, no se produce sobrecruzamiento. Para la selección del individuo a mutar se utilizan torneos en el que se incluye la edad de los individuos (número de generaciones que llevan en la población) como un factor decremental de su fitness. Se proponen dos tipos de mutaciones la primera se aplica a los hidden states (estados ocultos) y la segunda a las operaciones. En el primer caso, se crean nuevos enlaces entre las operaciones asegurándose de que no se forman bucles y en el segundo una operación se cambia aleatoriamente por otra.</p>
<p style="text-align:center;"><img src="https://aulaglobal.uc3m.es/draftfile.php/2631638/user/draft/292806929/image%20%282%29.png" alt=""></p>
<p align="center" style="font-family:sans-serif; font-size:12px; line-height:1.4em;">Figura 5.5 <a href="#ref:EvolvingNeural">[15]</a></p>

<h4 style="font-weight:bold; font-size:14px; font-family:sans-serif;" id="procesoProgresivo">Proceso progresivo de las decisiones</h4>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">En este enfoque se va añadiendo progresivamente nueva complejidad al modelo. Se empieza, por tanto, con operaciones y modelos muy sencillos para luego ir añadiendo nuevas capas, operaciones y conexiones en cada paso. En Progressive NAS <a href="#ref:RegularizedEvolution">[16]</a>, el enfoque propuesto es muy parecido al algoritmo A*, ya que se van expandiendo progresivamente nuevos nodos (nuevas arquitecturas). El factor de ramificación en este caso serían el número de cambios que se puede hacer a una arquitectura ya creada (e.g. incluir nuevas capas, eliminar neuronas). En A* se emplea una heurística para guiar la búsqueda, en el caso de PNAS utilizan la precisión del modelo en un conjunto de validación.</p>

<h3 style="font-weight:bold; font-size:16.8px; font-family:sans-serif;" id="estrategiaDeEvaluacion">Estrategia de evaluación</h3>
<h4 style="font-weight:bold; font-size:14px; font-family:sans-serif;" id="entrenamientoCero">Entrenamiento desde cero</h4>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Como en los algoritmos de búsqueda existe una manera sencilla de afrontar el problema de la evaluación, esto es el entrenamiento completo hasta que el modelo converja de cada una de las arquitecturas que se prueba. Sin embargo, además de ineficiente ––ya que por ejemplo en el enfoque de proceso progresivo de las decisiones los modelos muy sencillos iniciales y los más complejos conllevan el mismo nivel de evaluación––, este enfoque también es pobre, estadísticamente hablando, ya que se genera un único punto de evaluación. Lo más conveniente, como ya se hace en la validación cruzada, sería obtener distintas mediciones para distintos conjuntos de datos que permitan obtener una medición de rendimiento más fiable. Este enfoque fue utilizado por Zoph &amp; Le <a href="#ref:ProgressiveNeural">[17]</a>.</p>

<h4 style="font-weight:bold; font-size:14px; font-family:sans-serif;" id="proxyTask">Proxy task performance</h4>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Esta estrategia parte de la suposición de que los resultados que un modelo obtenga en problemas similares, pero más simples, del problema original se verán trasladados a este último. Puede, por tanto, intentar hacer evaluaciones con imágenes de menor resolución, menos ejemplos, menos ciclos, etc.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">El problema de esta estrategia es que la suposición inicial es probable que no se cumpla y los resultados de la exploración de arquitecturas dependerá en gran medida de si para el ámbito concreto la suposición hecha es válida.</p>

<h4 style="font-weight:bold; font-size:14px; font-family:sans-serif;" id="intercambioDeParametros">Intercambio de parámetros</h4>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">El intercambio de parámetros pretende solucionar el problema descrito en la sección 3.1 que tiene entrenar desde cero las distintas arquitecturas. Algunos investigadores han encontrado métodos para compartir los pesos aprendidos por algunas arquitecturas para poder usarlos en nuevas arquitecturas exploradas.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">La propuesta de EAS (Efficient Architecture Search) <a href="#ref:EfficientArchitecture">[18]</a>, propone un enfoque en el que un metacontrolador aprende a hacer cambios progresivos a las redes neuronales que no varían sustancialmente los resultados en la función de evaluación. De tal modo pueden preservarse los pesos aprendidos anteriormente para seguir aprendiendo.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Otra propuesta, ENAS (Efficient NAS) <a href="#ref:EfficientNeural">[19]</a> propone que los tipos de componentes de una red (e.g. 3x3 capa convolucional) tienen unas características comunes y, por tanto, estas pueden compartir parámetros con aquellas incluidas en la arquitectura.</p>
<p style="text-align:center;"><img src="https://aulaglobal.uc3m.es/draftfile.php/2631638/user/draft/292806929/image%20%287%29.png" alt="" style="font-size:.9375rem;font-family:'-apple-system', BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, 'Noto Sans', sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';"></p>
<p align="center" style="font-family:sans-serif; font-size:12px; line-height:1.4em;">Figura 5.6 <a href="#ref:EfficientArchitecture">[18]</a></p>

<h4 style="font-weight:bold; font-size:14px; font-family:sans-serif;" id="basadoEnPrediccion">Basado en predicciones</h4>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Esta última estrategia intenta predecir los pesos de las arquitecturas sin tener que hacer pruebas con conjuntos de validación ni compartir información sobre los parámetros. Para ello un artículo <a href="#ref:HyperNetworks">[20]</a> investigó la posibilidad de entrenar una red neuronal separada que aprenda cuáles han de ser los pesos de las arquitecturas. Por tanto, se elimina la necesidad de aprender a partir de ejemplos, ya que solo deben predecirse los pesos y luego evaluar la precisión de la arquitectura. Sin embargo, es necesario entrenar la red neuronal que haga estas predicciones. </p>

<h2 style="border-bottom:1px solid #a2a9b1; margin-top:1em; font-size:21px; font-family:'Linux Libertine', Georgia, Times, serif;" id="ventajasInconvenientes">Ventajas e inconvenientes frente a enfoques tradicionales</h2>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;"><br/></p>

<h2 style="border-bottom:1px solid #a2a9b1; margin-top:1em; font-size:21px; font-family:'Linux Libertine', Georgia, Times, serif;" id="areasAplicacion">Áreas de aplicación en IA</h2>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">En esta sección se detallan cinco áreas de aplicaciones de AutoML dentro del campo de la Inteligencia Artificial. En concreto, se exponen las implicaciones de esta tecnología en cada área de aplicación, sus beneficios y sus desventajas.</p>

<h3 style="font-weight:bold; font-size:16.8px; font-family:sans-serif;" id="vision">Visión</h3>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">El desarrollo de modelos basados en datos incompletos o no estructurados, como es el caso de las imágenes, no es una tarea fácil. Como ya se ha comentado, se requiere de científicos de datos que posean conocimientos específicos del dominio, capacidades de seleccionar el método que mejor funcione para un determinado negocio y competencias para poder implementar el sistema final.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">El uso de AutoML en el campo de la visión computacional ha ganado mucho valor en los últimos años. Google Cloud proporciona las herramientas y la potencia de cómputo necesarias para la utilización de esta novedosa tecnología. Este entorno recibe el nombre de AutoML Vision <a href="#ref:AutoMLVisionDocumentation">[21]</a>. Entre otras funcionalidades, permite al usuario crear modelos de clasificación de imágenes avanzados sin tener ningún tipo de conocimiento o experiencia previa en el campo.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">En rasgos generales, AutoML Vision proporciona una gran cantidad de imágenes de entrenamiento, las cuales tienen que ser necesariamente clasificadas por seres humanos. Cuando se ha entrenado el modelo con estas imágenes, Google Cloud <a href="#ref:AutoMLvision">[22]</a> proporciona una API que permite obtener la predicción que realiza el modelo en función de una determinada imagen.</p>

<h3 style="font-weight:bold; font-size:16.8px; font-family:sans-serif;" id="traduccion">Traducción</h3>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">En muchas situaciones empresariales puede ser necesaria la traducción automática y en tiempo real de textos, informes, opiniones, reportes, etc. Las empresas suelen contratar a personal especializado y experimentado en idiomas, lo que supone un alto coste económico y un elevado coste en tiempo.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">De igual manera que en la subsección anterior, Google Cloud proporciona otra API llamada AutoML Translation <a href="#ref:AutoMLTranslation">[23]</a>, la cual posee una enorme cantidad de idiomas, así como modelos preentrenados con textos de propósito general. La utilidad real de esta API, es que proporciona dichos modelos de manera general; pero el usuario puede añadir una capa más de especificidad para que la solución se ajuste a sus necesidades concretas.</p>

<h3 style="font-weight:bold; font-size:16.8px; font-family:sans-serif;" id="entrenamientoDispositivos">Entrenamiento de dispositivos móviles</h3>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Como se ha mencionado anteriormente, AutoML tiene un coste computacional muy bajo, por lo que es una solución perfecta para aplicar el aprendizaje automático en pequeños dispositivos. De esta manera, AutoML ha permitido un crecimiento exponencial de este tipo de tecnologías y hace que la IA sea mucho más accesible a los usuarios.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Incluso en algunos casos de estudio se ha utilizado AutoML para realizar Model Compression e intentar acelerar la velocidad de computación de dispositivos móviles con resultados bastante positivos.</p>
<p style="text-align:center;"><img src="https://aulaglobal.uc3m.es/draftfile.php/2631638/user/draft/55763622/imagen%20%282%29.png" alt=""></p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Esto plantea la pregunta de si en un futuro cercano AutoML podrá ser usado para otros dispositivos con poca capacidad de procesamiento como tablets o smartwatches <a href="#ref:aceleracionDispositivos">[24]</a>.</p>

<h3 style="font-weight:bold; font-size:16.8px; font-family:sans-serif;" id="dataMining">Data Mining</h3>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Debido a la gran escala de la web, las técnicas de data mining son cada vez más importantes para recaudar información relevante. La tarea más importante en este campo es obviamente la creación del modelo de aprendizaje. Esto es algo complicado para usuarios que deseen acceder a este tipo de tecnología y no tengan un conocimiento robusto de <em>data science, </em>por tanto, una de las soluciones dadas es AutoML <a href="#ref:dataMining">[25]</a>. De esta manera, tanto la elección de un modelo predictivo preciso como del ajuste de los parámetros son hechos por AutoML, lo que facilita mucho las cosas y hace más fácil la utilización y el entendimiento de este tipo de procesos.</p>

<h3 style="font-weight:bold; font-size:16.8px; font-family:sans-serif;" id="blockchain">Blockchain</h3>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Estos últimos meses el concepto de Blockchain ha estado en boca de todo el mundo debido a la muy discutida existencia de los NFT's. Aún así, la existencia del Blockchain es anterior a este concepto y AutoML ya estaba sacando partido de esta tecnología desde 2019 <a href="#ref:blockchain">[26]</a>. De esta manera, AutoML es capaz de automatizar el proceso de análisis de los datos generados por el blockchain (como la organización de los bloques, la transacción hecha, tokens generados, etc.), reduciendo enormemente su coste.</p>
<p style="text-align:center;"><img src="https://i.blogs.es/eb1a62/blockchain/450_1000.png" alt="Qué es blockchain: la explicación definitiva para la tecnología más de moda"></p>

<h2 style="border-bottom:1px solid #a2a9b1; margin-top:1em; font-size:21px; font-family:'Linux Libertine', Georgia, Times, serif;" id="casosDeUso">Casos específicos de uso</h2>
<h3 style="font-weight:bold; font-size:16.8px; font-family:sans-serif;" id="caso1">Identificación de perros callejeros</h3>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;"><br/></p>

<h3 style="font-weight:bold; font-size:16.8px; font-family:sans-serif;" id="caso2">Predicción de accidentes de tráfico</h3>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Los accidentes de tráfico son actualmente una de las mayores causas de muertes y lesiones, no solo en España, sino mundialmente. Alrededor de 1.35 millones de personas pierden la vida a causa de estos accidentes de tráfico. Se han propuesto numerosas soluciones a este grave problema, principalmente el diseño y desarrollo de sistemas que predicen los accidentes de tráfico, así como la gravedad de cada uno de los accidentes.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Esto es posible gracias a la gran cantidad de datos y al aprendizaje automático, que permite utilizar esos datos para realizar la predicción. Han surgido muchos métodos tradicionales de inteligencia artificial para realizar esta importante tarea. Estos no han sido del todo precisos para atender a todos los tipos de accidentes de tráfico que ocurren día a día, además de que no han sido capaces de manejar grandes volúmenes de datos. La decisión de qué técnica de machine learning era mejor para afrontar este problema era una tarea que demandaba mucho tiempo y esfuerzo físico y mental.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Por ello, en este contexto se decidió utilizar AutoML que permitía reducir los esfuerzos humanos, tiempos de desarrollo, etc.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Es en ese punto donde ha surgido el aprendizaje automático automatizado. El objetivo del uso del AutoML en este contexto fue conseguir reducir a la mitad el número total de muertes y lesiones producidas por estos accidentes. Para ello, se quería predecir los choques y clasificar su gravedad para proporcionar información de vital importancia para mejorar la gestión del flujo de tráfico y aumentar la seguridad vial <a href="#ref:casoCrash">[27]</a>.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Esta predicción está enfocada en generar modelos predictivos utilizando el histórico de datos basándose en datos nuevos y no vistos hasta el momento. En el ámbito del transporte y la conducción, es muy difícil extraer datos fiables y útiles para el desarrollo de modelos exitosos en la tarea de predicción. Por ello, en este contexto se utilizó el AutoML con el objetivo de encontrar, de manera automatizada la combinación de técnicas de procesamiento, algoritmos e hiperparámetros que maximizasen los resultados de las predicciones de los modelos.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Los resultados obtenidos con los modelos de AutoML fueron muy prometedores, puesto que se obtuvo en cada uno de los modelos, cómo mínimo un 80 % de precisión en 5 conjuntos de datos distintos, que fueron utilizados para probar estos modelos.</p>
<p style="text-align:center;"><img src="https://aulaglobal.uc3m.es/draftfile.php/2631638/user/draft/55763622/image.png" alt=""></p>

<h2 style="border-bottom:1px solid #a2a9b1; margin-top:1em; font-size:21px; font-family:'Linux Libertine', Georgia, Times, serif;" id="futurasAplicaciones">Futuras aplicaciones</h2>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Existen muchas teorías en referencia a las futuras aplicaciones que el aprendizaje automático automatizado puede brindar a la sociedad. Estas teorías o enfoques sobre el AutoML están tan desarrolladas que se puede llegar a cuestionar la competencia con los expertos en<i> machine learning</i> <a href="#ref:futuroAutoML">[28]</a>. Sin embargo, estos enfoques se enfrentan a un reto importante, la objetividad y automaticidad en la toma de decisiones guiada por los datos.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">En primer lugar, sabemos que la tarea de preprocesado o limpieza de datos es una tarea costosa, pesada y realmente, se trata de la tarea con más importancia dentro del aprendizaje automático, puesto que unos datos mal preprocesados pueden dar lugar a un aprendizaje incorrecto. Debido a la gran importancia de esta tarea, el aprendizaje automático automatizado se encargará de esta tarea, de manera que los humanos no tendremos que realizar este proceso de preprocesado de datos. Esto permite potenciar las capacidades de los científicos de datos, pues ya no se tendrán que enfocar en tareas repetitivas y podrán centrarse realmente en el análisis y solución de problemas. </p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Esto permitirá reducir notablemente los tiempos de desarrollo de los distintos proyectos tecnológicos además de que permite que más personas tengan acceso a esta herramienta de ML, limitando las tareas que requieren conocimiento específico al propio AutoML.</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">A pesar de esto, el aprendizaje automático automatizado nunca va a reemplazar la tarea de un científico de datos, puesto que siempre se va a requerir la presencia de un experto para guiar, corregir y revisar las tareas que se están automatizando. Además, siempre se van a necesitar expertos que analicen, escojan soluciones y tomen conclusiones acerca de los resultados obtenidos, tarea que no puede realizar el AutoML.</p>

<h2 style="border-bottom:1px solid #a2a9b1; margin-top:1em; font-size:21px; font-family:'Linux Libertine', Georgia, Times, serif;" id="conclusiones">Conclusiones</h2>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;"><br/></p>

<h2 style="border-bottom:1px solid #a2a9b1; margin-top:1em; font-size:21px; font-family:'Linux Libertine', Georgia, Times, serif;" id="bibliografia">Bibliografía</h2>
<div style="list-style-type:decimal; font-family:sans-serif; font-size:14px; line-height:1.6;">
    <ol>
        <li id="ref:automlStateOfTheArt">AutoML: A Survey of the State-of-the-Art. <a href="https://arxiv.org/abs/1908.00709">Acceso</a></li>
        <li id="ref:h2oAutoML">H2O AutoML:Automatic Machine Learning. <a href="https://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html">Acceso</a></li>
        <li id="ref:autoFEpython">Automated Feature Engineering in Python. Towards Data Science. 2018. <a href="https://towardsdatascience.com/automated-feature-engineering-in-python-99baf11cc219">Acceso</a></li>
        <li id="ref:autoFEtools">Automated Feature Engineering Tools. Medium. 2020. <a href="https://medium.com/analytics-vidhya/automated-feature-engineering-tools-44d00be56e3a">Acceso</a></li>
        <li id="ref:hpoTowards">Hyperparameters Optimization. Towards Data Science. 2019. <a href="https://towardsdatascience.com/hyperparameters-optimization-526348bb8e2d">Acceso</a></li>
        <li id="ref:hpoAutoML">Hyperparameters Optimization. AutoML. 2018. <a href="https://www.automl.org/automl/hpo-overview/">Acceso</a></li>
        <li id="ref:whatIsNAS">What is Neural Architecture Search? And why should you care? <a href="https://towardsdatascience.com/what-is-neural-architecture-search-and-why-should-you-care-1e22393de461">Acceso</a> </li>
        <li id="ref:NAS2020">Neural Architecture Search. 2020. <a href="https://lilianweng.github.io/lil-log/2020/08/06/neural-architecture-search.html">Acceso</a></li>
        <li id="ref:NeuralArchitecture">Neural Architecture Search with Reinforcement Learning, Barret Zoph, Quoc V. Le. <a href="https://arxiv.org/abs/1611.01578">Acceso</a></li>
        <li id="ref:DesigningNeural">Designing Neural Network Architectures using Reinforcement Learning. <a href="https://arxiv.org/abs/1611.02167">Acceso</a></li>
        <li id="ref:BowenBaker">Bowen Baker, Otkrist Gupta, Nikhil Naik, Ramesh Raskar. <a href="https://arxiv.org/abs/1707.07012">Acceso</a></li>
        <li id="ref:LearningTransferable">Learning Transferable Architectures for Scalable Image Recognition, Zoph et al. <a href="https://arxiv.org/abs/1707.07012">Acceso</a></li>
        <li id="ref:HierarchicalRepresentations">Hierarchical Representations for Efficient Architecture Search. <a href="https://arxiv.org/abs/1711.00436">Acceso</a></li>
        <li id="ref:RandomSearch">Random Search for Hyper-Parameter Optimization James Bergstra, Yoshua Bengio. <a href="https://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf">Acceso</a></li>
        <li id="ref:EvolvingNeural">Evolving Neural Networks through Augmenting Topologies; Kenneth O. Stanley, Kenneth O. Stanley. <a href="http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf">Acceso</a></li>
        <li id="ref:RegularizedEvolution">Regularized Evolution for Image Classifier Architecture Search; Esteban Real, Alok Aggarwal, Yanping Huang, Quoc V Le. <a href="https://arxiv.org/abs/1802.01548">Acceso</a></li>
        <li id="ref:ProgressiveNeural">Progressive Neural Architecture Search, Liu et al. <a href="https://arxiv.org/abs/1712.00559">Acceso</a></li>
        <li id="ref:EfficientArchitecture">Efficient Architecture Search by Network Transformation, Cai et al. <a href="https://arxiv.org/abs/1707.04873">Acceso</a></li>
        <li id="ref:EfficientNeural">Efficient Neural Architecture Search via Parameter Sharing, Pham et al. <a href="https://arxiv.org/abs/1802.03268">Acceso</a></li>
        <li id="ref:HyperNetworks">HyperNetworks, Ha et al. <a href="https://arxiv.org/abs/1609.09106">Acceso</a></li>
        <li id="ref:AutoMLVisionDocumentation">AutoML Vision Documentation. <a href="https://cloud.google.com/vision/automl/docs">Acceso</a></li>
        <li id="ref:AutoMLvision">AutoML Vision. Google Cloud. <a href="https://cloud.google.com/vision/automl/docs">Acceso</a></li>
        <li id="ref:AutoMLTranslation">AutoML Translation Documentation. <a href="https://cloud.google.com/translate/automl/docs">Acceso</a></li>
        <li id="ref:aceleracionDispositivos">Estudio sobre aceleración en dispositivos móviles. <a href="https://openaccess.thecvf.com/content_ECCV_2018/html/Yihui_He_AMC_Automated_Model_ECCV_2018_paper.html">Acceso</a></li>
        <li id="ref:dataMining">Uso de AutoML en Data Mining. <a href="https://www.mdpi.com/2076-3417/10/1/90">Acceso</a></li>
        <li id="ref:blockchain">Uso de AutoML en Blockchain. <a href="https://ieeexplore.ieee.org/abstract/document/8649758">Acceso</a></li>
        <li id="ref:casoCrash">A Case Study of AutoML for Supervised Crash Severity Prediction. <a href="https://www.researchgate.net/publication/351590401_A_Case_Study_of_AutoML_for_Supervised_Crash_Severity_Prediction">Acceso</a></li>
        <li id="ref:futuroAutoML">Machine Learning automatizado: El presente y futuro de los proyectos de ciencia datos. <a href="https://www.summan.com/2020/10/21/machine-learning-automatizado-el-presente-y-futuro-de-los-proyectos-de-ciencia-datos/">Acceso</a></li>
    </ol>
</div>

<h2 style="border-bottom:1px solid #a2a9b1; margin-top:1em; font-size:21px; font-family:'Linux Libertine', Georgia, Times, serif;" id="apendices">Apéndices</h2>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">NeurIPS 2018 - AutoML</p>
<a href="http://kaf.uc3m.es/browseandembed/index/media/entryid/1_zqvt8pb9/showDescription/false/showTitle/false/showTags/false/showDuration/false/showOwner/false/showUploadDate/false/playerSize/608x402/playerSkin/46017451/">tinymce-kalturamedia-embed||Automatic Machine Learning (02:09:47)||608||402</a>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">PyConES 2020 - Machine Learning para Vagos</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;"><a href="http://kaf.uc3m.es/browseandembed/index/media/entryid/1_r1a9ffxa/showDescription/false/showTitle/false/showTags/false/showDuration/false/showOwner/false/showUploadDate/false/playerSize/400x285/playerSkin/45786701/">tinymce-kalturamedia-embed||AutoML (Machine Learning para Vagos) - PyConES 2020 (17:40)||400||285</a></p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Ejemplos de AutoML en el campo del Procesamiento del Lenguaje</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;"><a href="http://kaf.uc3m.es/browseandembed/index/media/entryid/1_p2gq7eb8/showDescription/false/showTitle/false/showTags/false/showDuration/false/showOwner/false/showUploadDate/false/playerSize/400x285/playerSkin/45786701/">tinymce-kalturamedia-embed||Custom Sentiment Analysis with AutoML Natural Language (03:47)||400||285</a></p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;"><a href="http://kaf.uc3m.es/browseandembed/index/media/entryid/1_m9sv4qmd/showDescription/false/showTitle/false/showTags/false/showDuration/false/showOwner/false/showUploadDate/false/playerSize/400x285/playerSkin/45786701/">tinymce-kalturamedia-embed||Text Entity Extraction with AutoML Natural Language (03:26)||400||285</a></p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;">Visualización de AutoML para un Perceptrón multicapa</p>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;"><a href="http://kaf.uc3m.es/browseandembed/index/media/entryid/1_895nd1y4/showDescription/false/showTitle/false/showTags/false/showDuration/false/showOwner/false/showUploadDate/false/playerSize/400x285/playerSkin/45786701/">tinymce-kalturamedia-embed||Demo of AutoML (00:57)||400||285</a></p>

<h2 style="border-bottom:1px solid #a2a9b1; margin-top:1em; font-size:21px; font-family:'Linux Libertine', Georgia, Times, serif;" id="preguntas">Preguntas</h2>
<div style="list-style-type:decimal; font-family:sans-serif; font-size:14px; line-height:1.6;">
    <ol>
        <li>¿Qué significa la abreviación AutoML?</li>
        <li>¿Qué es AutoML a grandes rasgos?</li>
        <li>¿Sobre qué clase de problemas se puede utilizar AutoML?</li>
        <li>¿AutoML remplazará a los científicos de datos?</li>
        <li>¿Qué se necesita para emplear AutoML?</li>
        <li>¿Qué lo hace tan accesible?</li>
        <li>¿Qué fases del desarrollo de un modelo nos facilita AutoML?</li>
        <li>¿En qué consiste el Hyperparameter Optimization (HPO)?</li>
        <li>¿AutoML ha demostrado ser una técnica que ofrece resultados buenos?</li>
        <li>¿Por qué es posible usar AutoML en dispositivos móviles?</li>
        <li>¿Por qué resulta útil AutoML en Data Mining?</li>
        <li>¿Qué se deseaba mejorar en el caso de uso de la predicción de accidentes de tráfico?</li>
        <li>¿Con cuántos conjuntos de datos se trabajó en el caso de la predicción de accidentes? ¿Por qué es relevante utilizar varios conjuntos de datos?</li>
    </ol>
</div>
<h2 style="border-bottom:1px solid #a2a9b1; margin-top:1em; font-size:21px; font-family:'Linux Libertine', Georgia, Times, serif;" id="creditos">Créditos</h2>
<p align="justify" style="font-family:sans-serif; font-size:14px; line-height:1.6;"><br/></p>